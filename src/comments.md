[
    "A robust AI agent stack is essential for success. SmythOS offers cutting-edge AI agent solutions that may significantly improve your projects.",
    "How i will get this code",
    "You are very creative using tech to solve problems. Great work!",
    "cant you create a manager agent who does what agentops does? and juse your local compute power to complete this?",
    "Hello, one little question if you could help me. ¬øHow can I pass the result of one task to another arbitrary task ?",
    "Yapper trapper üòÇ",
    "Great tutorial! Perfect for beginners I appreciate it, Bro. Thanks!\r\n\r\nBy the way:\r\n1. Noticed an error with some URLs, specifically for llama3 Local, after spending some time üòä. It seems to come from the {vedio_id} passed in the agent prompt. It's recommended to use {{video_id}} instead, ensuring compatibility across OpenAI, Groq, and local LLM models.\r\n2. As you mentioned, errors are opportunities for learning. I've now incorporated a 401 check in the function `validate_video_id()`.\r\n3. Encountered an issue creating the `comment.md` file due to an emoji error (UnicodeEncodeError: 'charmap' codec can't encode character '\\U0001f64c'). The workaround involved creating both `comment.md` and `report.md` files, ensuring proper handling of comments with emojis in markdown files.\r\n4. Noticed that the `Report.md` didn't include the URL link. To address this, I made the following change in `main.py`:\r\n```python\r\ninURL = input(\"üöÄ Enter YouTube URL: \")\r\nvideo_id = extract_video_id(inURL)\r\ninputs = {\"video_id\": video_id, \"url\": inURL}\r\n```\n5. because of groq rate limit and wanting to test; used a OpenAI (of course limited it GPT3 üòú)\n```\n# OPenAI\r\n        self.openai_llm = ChatOpenAI(\r\n            temperature=0,\r\n            api_key=os.environ.get(\"OPENAI_API_KEY\"),\r\n            model_name=\"gpt-3.5-turbo\",\r\n        )\n```Thanks again, Bro! Fantastic tutorial! Thanks a lot, Doc! - Srikanth Kamathü§ü",
    "top top top",
    "Does this interests you? \n1. CodeCraft Duel: Super Agent Showdown\n2. Pixel Pioneers: Super Agent AI Clash\n3. Digital Duel: LLM Super Agents Battle\n4. Byte Battle Royale: Dueling LLM Agents\n5. AI Code Clash: Super Agent Showdown\n6. CodeCraft Combat: Super Agent Edition\n7. Digital Duel: Super Agent AI Battle\n8. Pixel Pioneers: LLM Super Agent Showdown\n9. Byte Battle Royale: Super Agent AI Combat\n10. AI Code Clash: Dueling Super Agents Edition",
    "Would be great if there was a frontend using Open WebUI together with Groq API.",
    "Great video! I'm liiter condused about the text processing after you get the comments from youtube. Is it not necessary to pass through the token and embedding process on that?",
    "bless!",
    "Tony, have you tested to see whether 'backstory' makes any difference to the output?\nI have tested this on a few models, and whether the backstory is positive (i.e. describes a human type role), neutral (leave empty or put none), or negative ( give a human role not relevant to task or a non-human role, e.g. cat), seems to make no significant difference to the output generated ..",
    "Oh boy! Oh boy! Oh boy! What a power packed knowledge bomb you just dropped. Man, you are killin' it. Great job, hands down. Started gen ai journey recently, watched a ton of videos, but the information you share, hardly I got from any other video. \nCould you please also create a video on fine tuning an llm? \nThank you a million.",
    "Great video, but I got  a little dizzy watching your screens consistently moving around, like a pop video.",
    "you're the man üï∂ :) keep up this great work !",
    "Interesting tutorial!",
    "Can you deploy these models using Ollama?",
    "How cost is calculated if you are using groq for free üòê!!!  I am still having some drawback in integration of agentops with crew",
    "For rate limit - use max_rpm = 2 or 4 for each agent",
    "How do we do it with the Claude API?\n\nIt might be able to ingest more.",
    "Jover",
    "What a powerhouse of a tutorial wow. Great work thank you!",
    "love this!",
    "Thank you for sharing this!\n\nHuge fan of your content."
]